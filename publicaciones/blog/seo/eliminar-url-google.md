---
title: Eliminar p√°gina o URL indexada en Google
description: Aprende a eliminar una URL de forma correcta y eficiente para que no vuelva a aparecer en Google
lang: es_ES
author: Emirodgar
sitemap: 1
feed: 1
folder: seo
layout: emirodgar_post
date: 19/05/2021
image: https://emirodgar.com/cdn/images/og/estrategia-seo.png
permalink: eliminar-url-google

---

Existe un gran desconocimiento sobre c√≥mo podemos hacer que nuestra p√°gina web o una URL de la misma sea desindexada correctamente de Google.

> Disponer √∫nicamente de p√°ginas de calidad es un [Factor SEO](factores-seo) cr√≠tico para cualquier estrategia. Por ello debemos evitar que los buscadores indexen aquellas que no aportan valor.

 **Prevenir que se indexe**

 - [Directiva noindex](#noindex)
 - [Bloqueo con disallow en robots.txt](#disallow) (no garantiza la no indexaci√≥n)

**Eliminar URL indexada**

 - Error 404 o 410
 - Redirecci√≥n 301
 - Herramienta de eliminaci√≥n de Google (temporal) + noindex

 

## 1. Prevenir la indexaci√≥n de una URL

Si a√∫n estamos a tiempo, es mejor prevenir la indexaci√≥n de nuestra p√°gina o secci√≥n por parte de los buscadores.

### 1.1. <a name="noindex"></a> Directiva noindex

> Para poder utilizar noindex dentro de una URL, √©sta debe ser accesible por los buscadores por lo que **no podemos bloquear su acceso a trav√©s del robots.txt**

La [directiva **noindex**](https://developers.google.com/search/reference/robots_meta_tag) puede ser implementada a trav√©s del header de la p√°gina. Bastar√° con incluir la meta robots con el valor **noindex**

```
<!DOCTYPE html>
<html><head>
<meta name="robots" content="noindex" />
_(‚Ä¶)_
</head>
<body>_(‚Ä¶)_</body>
</html>
```
Tambi√©n podr√≠amos configurarlo a nivel de servidor como una cabecera HTTP:

```
X-Robots-Tag: noindex
```
Siempre que un robot de b√∫squeda reciba la etiqueta robots con valor **noindex** la URL no ser√° indexada..

>  La [directiva noindex bajo robots.txt ya no funciona](https://searchengineland.com/google-to-stop-supporting-noindex-directive-in-robots-txt-319003) por lo que no debemos usarla.

### 1.2. <a name="disallow"></a>Disallow en robots.txt

> El fichero robots.txt podr√≠a ser ignorado por los buscadores por lo que no es una opci√≥n que garantice al 100% la no indexaci√≥n de la URL.

En el caso de que se trate de una secci√≥n amplia del sitio o que no tengamos acceso a dichas p√°ginas para poder implementar la directiva noindex, podemos hacer uso del comando disallow del robots.txt. Para ello debemos seguir el [est√°ndar de exclusi√≥n de robots](https://es.wikipedia.org/wiki/Est%C3%A1ndar_de_exclusi%C3%B3n_de_robots).

```
User-agent: *
Disallow: /cgi-bin/
Disallow: /tmp/
Disallow: /privado/
```

No obstante, como ya hemos comentado, el disallow **no garantiza la no indexaci√≥n** ya que lo que realmente hace es bloquear el rastreo de los robots.

## 2. Eliminar una URL ya indexada

En el caso de que la URL est√© indexada por los buscadores, adem√°s de seguir los pasos del punto anterior, podemos hacer lo siguiente para acelerar y agilizar el proceso:

 1. Forzar un error 404 o error 410 (√©ste √∫ltimo suele ser m√°s r√°pido)
 2. Aplicar una redirecci√≥n 301 (suele generar un error *[404 soft](https://support.google.com/webmasters/answer/181708?hl=es)* en Google Search Console)

Como curiosidad, John Mueller confirm√≥ a trav√©s de Twitter que siempre que exista un enlace externo hacia una de nuestras URLs, aunque √©sta muestre un error 404, Google seguir√° intentando indexarla de vez en cuando.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">As long as we have signals for that URL (even if it&#39;s just a random link somewhere), we&#39;ll keep trying it from time to time.</p>&mdash; üçå John üçå (@JohnMu) <a href="https://twitter.com/JohnMu/status/1107298611128352769?ref_src=twsrc%5Etfw">March 17, 2019</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


## Herramientas de Google

Google pone a nuestra disposici√≥n dos herramientas, la primera para poder [eliminar contenido puntual desde Google Search Console](https://www.google.com/webmasters/tools/url-removal) y la segunda para [eliminar contenido obsoleto](https://www.google.com/webmasters/tools/removals). Ambas no garantizan su eliminaci√≥n y, de hacerlo, se trata de una **acci√≥n temporal** por lo que tendr√° validez √∫nicamente durante 90 d√≠as. A partir de entonces, podr√≠a volver a ser indexado.

## Consejos adicionales

En el caso de muchas URLs que, tras un tiempo publicadas, no queremos que sigan indexadas, podemos hacer uso de la etiqueta  [unavailable_after](https://googleblog.blogspot.com/2007/07/robots-exclusion-protocol-now-with-even.html)  de tal forma que ya vamos preparando el terreno para que, a corto plazo, Google las desindexe. Yo la suelo utilizar para p√°ginas de eventos.

En el caso de que queramos que desaparezca informaci√≥n alojada en otras p√°ginas y que est√°n incumpliendo las normas, podemos  [seguir estos pasos](https://support.google.com/webmasters/answer/6332384?hl=es#more_information)  ya que debemos hacerlo a trav√©s del  [portal legal de Google](https://support.google.com/legal/answer/3110420?visit_id=1-636652569480291557-3013440154&rd=1).

Tags: {{page.tags}}
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTIwNjM2MTUyNjIsMTczNjY4NjAzOSwtOT
QxNDg3MTAsLTczOTI0ODYxOSwxMDQ3NzgxNzUyLDI2OTI2NjMz
OV19
-->